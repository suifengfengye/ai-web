{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef80799a-fe94-4706-9ca0-9f6f6f66708d",
   "metadata": {},
   "source": [
    "# 1、FactualCorrectness的使用\n",
    "\n",
    "```python\n",
    "from ragas.metrics import FactualCorrectness\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df303a93-6789-4b0f-9911-66d857418eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/huggingface/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SingleTurnSample(user_input='为什么说端侧AI手机更容易刺激高端用户的换机需求？', retrieved_contexts=['进一步看，明年高端智能手机出货量有望继续跑赢整体大盘。其一，从供应 端来看，明年会更多端侧AI 手机上市，从给高端智能手机带来新的产品。 其次，从需求角度看，端侧AI 手机更加容易刺激高端用户的换机需求。配 合长换机期下的高端需求增量，高端智能手机需求也有望继续提升。', '二、端侧 AI 大模型快速落地，带动端云协同需求', '从更长期的时间维度看，端侧 AI 需求会拉动整体 AI 算力芯片训练端的需 求，拓展AI 算力芯片的增长边界。长期来看，作为具身智能载体，人形机 器人有潜力超过智能手机和汽车等终端行业的规模，带来更大的AI 算力芯 片需求增量。', '2)为了更好地提升 C 端用户体验，终端品牌厂商同样需要云端的 AI 算力来 训练自身的大模型，从而大幅提升小参数量的端侧模型能力。这是从端侧推 理体验需求反哺云侧训练算力需求提升，再次带动云侧AI 算力的增长。\\n首先，具备端侧 AI 大模型能力的终端设备出货量大幅提升，带动具备更高AI 算力芯片出货量提升。在近半年来，无论是智能手机品牌、笔记本电脑品 牌，还是新能源车企都在发布具备端侧AI 能力的终端产品。生成式 AI 正在 快速渗透到各种电子终端中。因此，AI 算力芯片在端侧的需求也在大幅增长。'], reference_contexts=['进一步看，明年高端智能手机出货量有望继续跑赢整体大盘。其一，从供应 端来看，明年会更多端侧AI 手机上市，从给高端智能手机带来新的产品。 其次，从需求角度看，端侧AI 手机更加容易刺激高端用户的换机需求。配 合长换机期下的高端需求增量，高端智能手机需求也有望继续提升。'], response='端侧AI手机更容易刺激高端用户的换机需求，主要是因为这些设备能够提供更加智能和个性化的使用体验。随着技术的进步，端侧AI手机能够更好地理解和预测用户的需求，从而提供更符合个人习惯的服务与应用，这自然会吸引那些追求最新科技并希望获得更好用户体验的高端用户群体。为了享受最新的技术和功能，这部分用户可能会选择更换他们的智能手机。', multi_responses=None, reference='由于端侧AI手机能够提供更多新的功能和体验，从而更有可能吸引现有的高端用户进行设备升级或更换。这与普通智能手机相比，具有更强的吸引力和竞争力。', rubrics=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 准备样本\n",
    "from ragas import SingleTurnSample\n",
    "sample_data = {\n",
    "    \"user_input\": \"为什么说端侧AI手机更容易刺激高端用户的换机需求？\", \n",
    "    \"reference\": \"由于端侧AI手机能够提供更多新的功能和体验，从而更有可能吸引现有的高端用户进行设备升级或更换。这与普通智能手机相比，具有更强的吸引力和竞争力。\", \n",
    "    \"response\": \"端侧AI手机更容易刺激高端用户的换机需求，主要是因为这些设备能够提供更加智能和个性化的使用体验。随着技术的进步，端侧AI手机能够更好地理解和预测用户的需求，从而提供更符合个人习惯的服务与应用，这自然会吸引那些追求最新科技并希望获得更好用户体验的高端用户群体。为了享受最新的技术和功能，这部分用户可能会选择更换他们的智能手机。\", \n",
    "    \"retrieved_contexts\": [\"进一步看，明年高端智能手机出货量有望继续跑赢整体大盘。其一，从供应 端来看，明年会更多端侧AI 手机上市，从给高端智能手机带来新的产品。 其次，从需求角度看，端侧AI 手机更加容易刺激高端用户的换机需求。配 合长换机期下的高端需求增量，高端智能手机需求也有望继续提升。\", \"二、端侧 AI 大模型快速落地，带动端云协同需求\", \"从更长期的时间维度看，端侧 AI 需求会拉动整体 AI 算力芯片训练端的需 求，拓展AI 算力芯片的增长边界。长期来看，作为具身智能载体，人形机 器人有潜力超过智能手机和汽车等终端行业的规模，带来更大的AI 算力芯 片需求增量。\", \"2)为了更好地提升 C 端用户体验，终端品牌厂商同样需要云端的 AI 算力来 训练自身的大模型，从而大幅提升小参数量的端侧模型能力。这是从端侧推 理体验需求反哺云侧训练算力需求提升，再次带动云侧AI 算力的增长。\\n首先，具备端侧 AI 大模型能力的终端设备出货量大幅提升，带动具备更高AI 算力芯片出货量提升。在近半年来，无论是智能手机品牌、笔记本电脑品 牌，还是新能源车企都在发布具备端侧AI 能力的终端产品。生成式 AI 正在 快速渗透到各种电子终端中。因此，AI 算力芯片在端侧的需求也在大幅增长。\"], \n",
    "    \"retrieved_contexts_ids\": [\"78a6ff51-e183-40a7-a38b-3fb989a0a9c9\", \"b61e7961-f2e7-4457-b8ea-2521b3c63df5\", \"f67e88cc-8c38-4e28-b0bd-63e071db6400\", \"b336442e-c280-4c21-ace5-b35e16f1b8cc\"], \n",
    "    \"reference_contexts_ids\": [\"78a6ff51-e183-40a7-a38b-3fb989a0a9c9\"], \n",
    "    \"reference_contexts\": [\"进一步看，明年高端智能手机出货量有望继续跑赢整体大盘。其一，从供应 端来看，明年会更多端侧AI 手机上市，从给高端智能手机带来新的产品。 其次，从需求角度看，端侧AI 手机更加容易刺激高端用户的换机需求。配 合长换机期下的高端需求增量，高端智能手机需求也有望继续提升。\"]\n",
    "}\n",
    "sample = SingleTurnSample(\n",
    "    **sample_data,\n",
    ")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c000d0-ba89-415d-a285-75366e1f5d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 创建指标\n",
    "from ragas.metrics import FactualCorrectness\n",
    "from langchain_ollama import ChatOllama\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5:latest\")\n",
    "\n",
    "metric = FactualCorrectness(\n",
    "    atomicity=\"low\",\n",
    "    coverage=\"high\",\n",
    "    llm=LangchainLLMWrapper(llm),\n",
    ")\n",
    "\n",
    "await metric.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf17808-4e47-4d1f-84a1-565ab9f370d5",
   "metadata": {},
   "source": [
    "# 2. FactualCorrectness详解\n",
    "\n",
    "参数：\n",
    "- name: str, 指标名称,默认为\"factual_correctness\"\n",
    "\n",
    "*******************************************************************\n",
    "\n",
    "- mode: 计算结果的模式, 默认值为\"f1\",可选值为: \"precision\" / \"recall\" / \"f1\"\n",
    "- beta: beta系数，用于调节f1分数，在mode为\"f1\"时有效，mode为\"precision\"/\"recall\"无效。\n",
    "*******************************************************************\n",
    "- atomicity: 原子性,默认为\"low\",可选值为: \"low\" / \"high\"\n",
    "- coverage: 覆盖范围,默认为\"low\",可选值为: \"low\" / \"high\"\n",
    "- claim_decomposition_prompt: 主张分解提示词。\n",
    "- nli_prompt: NLI(Natural Language Inference, 自然语言推理)提示词。\n",
    "*******************************************************************\n",
    "- _required_columns: 需要在数据信息, [\"response\", \"reference\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4a2e5-86a6-4361-8c51-de72e6657158",
   "metadata": {},
   "source": [
    "## 2.1 claim_decomposition_prompt - 主张分解提示词\n",
    "\n",
    "1. 提示词内容：\n",
    "\n",
    "\"Decompose and break down each of the input sentences into one or more standalone statements. Each statement should be a standalone claim that can be independently verified.\n",
    "    Follow the level of atomicity and coverage as shown in the examples.\"\n",
    "\n",
    "中文翻译:\n",
    "\n",
    "将每个输入句子分解成一个或多个独立的陈述。每个陈述都应是一个独立的声明，可以独立验证。\n",
    "请遵循示例中所示的原子性和覆盖率级别。\n",
    "\n",
    "2. 例子：\n",
    "\n",
    "原始句子：\"Charles Babbage was a French mathematician, philosopher, and food critic.\"\n",
    "\n",
    "中文翻译：\"查尔斯·巴贝奇是一位法国数学家、哲学家和美食评论家。\"\n",
    "\n",
    "    1. 低原子性低覆盖率 - LOW_ATOMICITY_LOW_COVERAGE\n",
    "      Charles Babbage was a mathematician and philosopher.\n",
    "\n",
    "    2. 低原子性高覆盖率 - LOW_ATOMICITY_HIGH_COVERAGE\n",
    "      Charles Babbage was a French mathematician, philosopher, and food critic.\n",
    "\n",
    "    3. 高原子性低覆盖率 - HIGH_ATOMICITY_LOW_COVERAGE\n",
    "      Charles Babbage was a mathematician.\n",
    "      Charles Babbage was a philosopher.\n",
    "\n",
    "    4. 高原子性高覆盖率 - HIGH_ATOMICITY_HIGH_COVERAGE\n",
    "      Charles Babbage was a mathematician.\n",
    "      Charles Babbage was a philosopher.\n",
    "      Charles Babbage was a food critic.\n",
    "      Charles Babbage was French."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857691e-3de0-49b1-a3e8-e88ebb0d0278",
   "metadata": {},
   "source": [
    "## 2.2 nli_prompt - NLI提示词\n",
    "\n",
    "提示词内容：\n",
    "\n",
    "Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.\n",
    "\n",
    "中文翻译：\n",
    "\n",
    "你的任务是根据给定的上下文判断一系列语句的真实性。对于每个语句，如果该语句可以根据上下文直接推断出来，则返回判定结果 1；如果该语句无法根据上下文直接推断出来，则返回判定结果 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58c7b61-0432-4963-a16d-55f0598062c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考答案\n",
    "reference = \"Charles Babbage was a English mathematician, philosopher, and inventor.\"\n",
    "# 回答\n",
    "response = \"Charles Babbage was a French mathematician, philosopher, and food critic.\"\n",
    "response_claims = [\n",
    "  \"Charles Babbage was a mathematician.\",\n",
    "  \"Charles Babbage was a philosopher.\",\n",
    "  \"Charles Babbage was a food critic.\",\n",
    "  \"Charles Babbage was French.\"\n",
    "]\n",
    "reference_claims = [\n",
    "  \"Charles Babbage was a mathematician.\",\n",
    "  \"Charles Babbage was a philosopher.\",\n",
    "  \"Charles Babbage was a inventor.\",\n",
    "  \"Charles Babbage was English.\"\n",
    "]\n",
    "# 1. 精确度计算 precision = tp / (tp + fp)\n",
    "# 2. 召回率计算, recall = tp / (tp + fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485484a-3788-48b4-b7a0-6cd291dd5242",
   "metadata": {},
   "source": [
    "## 2.3 结果计算\n",
    "\n",
    "- precision - 精确度\n",
    "- recall - 召回率\n",
    "- f1: F1分数,1是一个调节参数，使用beta进行调节；\n",
    "    - 当beta=1时，精确度和召回率同等重要\n",
    "    - 当beta > 1时，更侧重召回率\n",
    "    - 当beta < 1时，更侧重精确度.\n",
    "\n",
    "$$\n",
    "F1 = (1 + \\beta^2) \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\beta^2 \\cdot \\text{precision} + \\text{recall}}\n",
    "$$\n",
    "\n",
    "场景：\n",
    "\n",
    "1. 信息检索系统：希望结果既准确（高精确率）又全面（高召回率），β 设置为1即可。\n",
    "2. 【高召回率】医学诊断：对于严重疾病，更关注召回率，以避免漏诊（高 β 值，如 F2）。\n",
    "3. 【高精确度】垃圾邮件过滤：更重视精确率，减少正常邮件被误判为垃圾邮件的概率（低 β 值，如 F0.5）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ba9df0-45c0-42e1-aa88-9983e9b6a563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:1.0\n",
      "recall:0.5\n"
     ]
    }
   ],
   "source": [
    "# 1. 精确度高，召回率低的例子\n",
    "# 参考答案\n",
    "reference = \"Charles Babbage was a English mathematician, philosopher, and inventor.\"\n",
    "# 回答\n",
    "response = \"Charles Babbage was a mathematician, philosopher\"\n",
    "response_claims = [\n",
    "  \"Charles Babbage was a mathematician.\",\n",
    "  \"Charles Babbage was a philosopher.\",\n",
    "]\n",
    "reference_claims = [\n",
    "  \"Charles Babbage was a mathematician.\",\n",
    "  \"Charles Babbage was a philosopher.\",\n",
    "  \"Charles Babbage was a inventor.\",\n",
    "  \"Charles Babbage was English.\"\n",
    "]\n",
    "# 1. 精确度计算 precision = tp / (tp + fp)\n",
    "precision = 2 / (2 + 0)\n",
    "print(f\"precision:{precision}\")\n",
    "# 2. 召回率计算, recall = tp / (tp + fn)\n",
    "recall = 2 / (2 + 2)\n",
    "print(f\"recall:{recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe41386-17b8-4b4c-9019-d4212331ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:0.6666666666666666, recall:1.0\n"
     ]
    }
   ],
   "source": [
    "# 2. 精确度低，召回率高的例子\n",
    "# 参考答案\n",
    "reference = \"Charles Babbage was a English mathematician, philosopher, and inventor.\"\n",
    "# 回答\n",
    "response = \"\"\"Charles Babbage was a French mathematician, philosopher, and food critic. \n",
    "And Charles Babbage was English, and inventor\"\"\"\n",
    "response_claims = [\n",
    "  \"Charles Babbage was a mathematician.\",\n",
    "  \"Charles Babbage was a philosopher.\",\n",
    "  \"Charles Babbage was a food critic.\",\n",
    "  \"Charles Babbage was French.\",\n",
    "    \"Charles Babbage was English.\",\n",
    "    \"Charles Babbage was a inventor.\",\n",
    "]\n",
    "reference_claims = [\n",
    "  \"Charles Babbage was a mathematician.\",\n",
    "  \"Charles Babbage was a philosopher.\",\n",
    "  \"Charles Babbage was a inventor.\",\n",
    "  \"Charles Babbage was English.\"\n",
    "]\n",
    "# 1. 精确度计算 precision = tp / (tp + fp)\n",
    "tp = 4\n",
    "fp = 2\n",
    "fn = 0\n",
    "precision = tp / (tp + fp)\n",
    "# 2. 召回率计算, recall = tp / (tp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "print(f\"precision:{precision}, recall:{recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1137d061-7d64-4e32-993d-0228293d1dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857142\n"
     ]
    }
   ],
   "source": [
    "# 3. f beta分数 计算的公式\n",
    "precision = 0.6666666666666666\n",
    "recall = 1.0\n",
    "beta = 0.5\n",
    "f1 = (1 + beta**2) * (precision * recall)/( beta**2 * precision + recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f1f954-eaad-47dc-8cc4-b82cba7df39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 加权调和平均数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c195cd0-29f7-4e5e-8bf5-1c308e486bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
