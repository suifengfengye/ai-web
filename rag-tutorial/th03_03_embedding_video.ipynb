{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b916c9-00d1-4a06-8142-69e7a263212f",
   "metadata": {},
   "source": [
    "# 1. embedding_function\n",
    "\n",
    "```python\n",
    "collection = client.get_or_create_collection(name=\"my_collection\", embedding_function=emb_fn)\n",
    "```\n",
    "\n",
    "BERT模型：BERT的全称是“Bidirectional Encoder Representations from Transformers”，中文为“多Transformer的双向编码器表示法”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6fbea3-0970-47cb-9488-681c96dc3eed",
   "metadata": {},
   "source": [
    "## 1.1 transformer\n",
    "![alt 属性文本](./image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c31e39-36b6-45ba-8a6f-684e4a1301fc",
   "metadata": {},
   "source": [
    "## 1.2 embedding方式\n",
    "\n",
    "1. SentenceTransformers模型   \n",
    "2. 封装的第三方服务商的embedding服务（得花钱）\n",
    "3. 自己搭建的embedding服务\n",
    "4. 自定义embedding\n",
    "\n",
    "```python\n",
    "from chromadb.utils import embedding_functions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671e851-c284-424a-948d-028ae88f3480",
   "metadata": {},
   "source": [
    "### 1.2.1 SentenceTransformers\n",
    "\n",
    "chroma默认使用的就是SentenceTransformers库中支持的all-MiniLM-L6-v2。[官方文档](https://www.sbert.net/)\n",
    "\n",
    "[支持的模型列表](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html)\n",
    "\n",
    "默认会从huggingface下载模型，\n",
    "- 默认macOS地址为：~/.cache/huggingface/hub\n",
    "- 默认的window地址为：C:\\Users\\<YourUsername>\\.cache\\huggingface\\hub\n",
    "\n",
    "```python\n",
    "from chromadb.utils import embedding_functions\n",
    "st_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"\",\n",
    "    cache_folder=\"\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb0ddc-c3fe-4a08-a0c3-0ee1291f8f7b",
   "metadata": {},
   "source": [
    "### 1.2.2 封装的第三方服务商的embedding服务（得花钱）\n",
    "国内访问不了。\n",
    "\n",
    "1. OpenAI\n",
    "2. Google\n",
    "3. Cohere\n",
    "4. HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ad8f0-039f-4c9e-adca-ef0a8e315a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=\"YOUR_API_KEY\",\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5d542-5e9b-43fb-8e2b-f5cd17ebc6bf",
   "metadata": {},
   "source": [
    "### 1.2.3 自己搭建的embedding服务\n",
    "\n",
    "1. ollama: [文档地址](https://docs.trychroma.com/integrations/embedding-models/ollama) 【注意这个文档的示例有问题。】\n",
    "2. huggingface server: 是将HuggingFace的文本嵌入服务的docker镜像，在本地跑起来。[文档地址](https://docs.trychroma.com/integrations/embedding-models/hugging-face-server)\n",
    "\n",
    "```python\n",
    "from chromadb.utils import embedding_functions\n",
    "ollama_ef = embedding_functions.OllamaEmbeddingFunction(\n",
    "    url=\"http://localhost:11434/api/embeddings\",\n",
    "    model_name=\"nomic-embed-text\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779c4181-957b-4dfd-b5c4-567e9bdf99eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "ollama_ef = embedding_functions.OllamaEmbeddingFunction(\n",
    "    url=\"http://localhost:11434/api/embeddings\",\n",
    "    model_name=\"nomic-embed-text\",\n",
    ")\n",
    "results = ollama_ef([\"文档0001\", \"文档0002\"])\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93374b-f1f6-4db8-8464-89945f2fe8f5",
   "metadata": {},
   "source": [
    "### 1.2.4 自定义embedding\n",
    "\n",
    "```python\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        # embed the documents somehow\n",
    "        return embeddings\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536c28e4-420e-4de5-9e11-903b13a42376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.tencent.com/pypi/simple/, https://mirrors.tencent.com/repository/pypi/tencent_pypi/simple\n",
      "Collecting openai\n",
      "  Downloading https://mirrors.tencent.com/yun/pypi/packages/15/64/db3462b358072387b8e93e6e6a38d3c741a17b4a84171ef01d6c85c63f25/openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached https://mirrors.tencent.com/yun/pypi/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached https://mirrors.tencent.com/yun/pypi/packages/3c/c1/6da849640cd35a41e91085723b76acc818d4b7d92b0b6e5111736ce1dd10/jiter-0.8.2-cp312-cp312-macosx_11_0_arm64.whl (310 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/miniconda3/envs/rag-video/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 openai-1.63.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99fc5f14-d12a-488b-a27a-bba1c829f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from openai import OpenAI\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model_name, api_key=\"\", base_url=\"\"):\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        \n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "        response = client.embeddings.create(\n",
    "            input=input,\n",
    "            model=self.model_name\n",
    "        )\n",
    "        # print(response)\n",
    "        embeddings = [item.embedding for item in response.data]\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d044aa36-e6b4-4df5-ba1e-1f153c1242e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-2.8312918e-02,  2.2436652e-02,  4.8403348e-05, ...,\n",
       "        -7.2233942e-03, -1.5576170e-03,  1.2797718e-02], dtype=float32),\n",
       " array([-0.02656638,  0.01375132,  0.008637  , ..., -0.00215925,\n",
       "        -0.00118349,  0.01302572], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "api_key = getpass.getpass()\n",
    "\n",
    "my_embedding_fn = MyEmbeddingFunction(\n",
    "    model_name=\"embedding-3\",\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "results = my_embedding_fn([\"文档0001\", \"文档0002\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d351c11-d15a-4316-87be-874279ac22ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.00863519, -0.00956835, -0.01586368, ..., -0.00673057,\n",
       "        -0.00711359, -0.01958238], dtype=float32),\n",
       " array([-0.01486283, -0.00533767, -0.0116189 , ...,  0.00653262,\n",
       "        -0.02319649,  0.00046317], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://yunwu.ai/v1/embeddings\n",
    "# import getpass\n",
    "\n",
    "api_key = \"sk-ArmSDkeRAgNp2L7RS0Sq39KVKxMOyddAtT6zXqJfpRjsziyd\"\n",
    "\n",
    "my_embedding_fn = MyEmbeddingFunction(\n",
    "    # model_name=\"embedding-3\",\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://yunwu.ai/v1\"\n",
    ")\n",
    "results = my_embedding_fn([\"文档0001\", \"文档0002\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606f4a7-3c74-49dd-ac1b-aa1e6d0d9a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
