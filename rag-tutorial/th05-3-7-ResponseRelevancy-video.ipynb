{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad301f14-64ad-49f6-ba61-60fd1c49ddd8",
   "metadata": {},
   "source": [
    "# 1. ResponseRelevancy / AnswerRelevancy\n",
    "\n",
    "响应（回答）相关性。输出为0 ～ 1之间，越接近 0 说明效果越差，越接近 1 说明效果越好。\n",
    "\n",
    "\n",
    "参数：\n",
    "\n",
    "- name: str, 指标名称,默认为\"answer_relevancy\"\n",
    "- question_generation: 根据response(回答)生成问题的提示词。\n",
    "- strictness: int, 默认值为3。执行 strictness 次，将 question_generation 提示词传递给LLM，得到输出。\n",
    "- embeddings: BaseRagasEmbeddings, 将 LLM 生成的问题，和真正的问题进行embedding处理，得到对应的向量。\n",
    "  \n",
    "  ```python\n",
    "  from ragas.embeddings import LangchainEmbeddingsWrapper, LlamaIndexEmbeddingsWrapper\n",
    "  from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "  ```\n",
    "\n",
    "*******************************************************************\n",
    "- _required_columns: 需要在数据信息, [\"user_input\",\"response\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad33f8-79cd-400d-8e1d-0cd81c5707eb",
   "metadata": {},
   "source": [
    "## 1.1 question_generation提示词\n",
    "\n",
    "1. 提示词内容：\n",
    "\n",
    "\"Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don't know\" or \"I'm not sure\" are noncommittal answers\"\n",
    "\n",
    "中文翻译:\n",
    "\n",
    "生成一个针对给定答案的问题，并判断该答案是否为“非承诺性回答”。如果答案是非承诺性的，输出 noncommittal 为 1；如果答案是明确的、有承诺性的，则输出 0。\n",
    "非承诺性回答指的是那些含糊其辞、模棱两可或逃避问题的回答。例如，“我不知道”或“我不确定”就属于非承诺性回答。\n",
    "\n",
    "2. 例子：\n",
    "\n",
    "例子1:\n",
    "\n",
    "原始句子(user_input)：\"Where was Albert Einstein born?\"\n",
    "\n",
    "原始句子(respone)：\"Albert Einstein was born in Germany.\"\n",
    "\n",
    "输出：noncommittal = 0\n",
    "\n",
    "中文翻译：\n",
    "\n",
    "原始句子(user_input)：\"阿尔伯特·爱因斯坦出生在哪里？\"\n",
    "\n",
    "原始句子(respone)：\"阿尔伯特·爱因斯坦出生于德国。\"\n",
    "\n",
    "例子2:\n",
    "\n",
    "原始句子(user_input)：\"What was the groundbreaking feature of the smartphone invented in 2023?\"\n",
    "\n",
    "原始句子(respone)：\"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022.\"\n",
    "\n",
    "输出：noncommittal = 1\n",
    "\n",
    "中文翻译：\n",
    "\n",
    "原始句子(user_input)：\"2023 年发明的智能手机的突破性功能是什么？\"\n",
    "\n",
    "原始句子(respone)：\"我不知道 2023 年发明的智能手机有何突破性功能，因为我不知道 2022 年以后的信息。\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61caaec2-a8c9-4f34-b683-d28021e431c5",
   "metadata": {},
   "source": [
    "## 1.2 评估过程：\n",
    "1. 根据响应（response，或者说是\"回答\"）让LLM提出几个和这个回答相关的问题，并输出答案相对于问题是否为“非承诺性回答”；如a_q1/a_q2/a_q3。是“非承诺性回答”输出\"1\",否输出\"0\"。假设输出为 [0, 0, 1]。\n",
    "    1.  **非承诺性回答**，noncommittal: 指的是那些含糊其辞、模棱两可或逃避问题的回答。\n",
    "3. 将a_q1/a_q2/a_q3 与 问题(user_input) 进行embedding得到向量，再计算余弦相似度。假设余弦相似度为: [0.8, 0.65, 0.4]\n",
    "4. 计算 [0.8, 0.65, 0.4].mean() * int(not numpy.any([0, 0, 1])), 得到结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7f6810-d80e-423c-87d1-38f7bccaa829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████| 67/67 [03:44<00:00,  3.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.7911}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate, RunConfig\n",
    "from ragas.metrics import ResponseRelevancy\n",
    "from langchain_ollama import ChatOllama\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from ragas import EvaluationDataset\n",
    "\n",
    "dataset = EvaluationDataset.from_jsonl(\"questions_answers_01.txt\")\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5:latest\")\n",
    "\n",
    "metric = ResponseRelevancy(\n",
    "    # atomicity=\"low\",\n",
    "    # coverage=\"high\",\n",
    "    # llm=LangchainLLMWrapper(llm),\n",
    "    embeddings=LangchainEmbeddingsWrapper(OllamaEmbeddings(model=\"nomic-embed-text:latest\"))\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[metric],\n",
    "    llm=LangchainLLMWrapper(llm),\n",
    "    run_config=RunConfig(\n",
    "        timeout=600,\n",
    "        max_retries=3,\n",
    "        max_workers=4\n",
    "    ),\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58b73a4-3984-4198-8f7f-ccc9b4810450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                            ID              SIZE      MODIFIED     \n",
      "qwen3:latest                    e4b5fd7f8af0    5.2 GB    6 weeks ago     \n",
      "bge-large:latest                b3d71c928059    670 MB    6 weeks ago     \n",
      "dxh_ai/dxh_0.5B:latest          a3c50c65335f    994 MB    2 months ago    \n",
      "Qwen2.5-0.5B-Instruct:latest    a3c50c65335f    994 MB    2 months ago    \n",
      "nomic-embed-text:latest         0a109f422b47    274 MB    5 months ago    \n",
      "qwen2.5:latest                  845dbda0ea48    4.7 GB    6 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5c6af-bff3-45d4-868a-9cba8a7e36c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
