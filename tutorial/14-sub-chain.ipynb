{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde7cd1f-714b-4fc7-8a99-e5eb9ad528c9",
   "metadata": {},
   "source": [
    "# 14-1 sub-chain\n",
    "\n",
    "目标例子：\n",
    "\n",
    "- 如果输入是中文，使用ChatZhipuAI回答\n",
    "- 其他，使用ChatOllama回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf631b-9ab5-42dc-bed1-5cb6bd292334",
   "metadata": {},
   "source": [
    "## (1) 将一个函数转换成 runnable的函数\n",
    "1. @chain装饰器\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import chain\n",
    "```\n",
    "  \n",
    "2. RunnableLambda()\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "```\n",
    "runnable_func为普通函数，但是经过@chain/RunnableLambda包装\n",
    "```python\n",
    "chain = prompt | chat_model | runnable_func\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c63ba9-0e34-456b-a0cc-452ee5a3054c",
   "metadata": {},
   "source": [
    "## (2) 中文字符判断\n",
    "\n",
    "```python\n",
    "import re\n",
    "text = \"这里有中文～～～\"\n",
    "pattern = re.compile(r'[\\u4e00-\\u9fff]')\n",
    "pattern.search(text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923bf4d6-20f7-4a5d-810f-b213bd8a370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# {\"question\":\"xxxxx\"}\n",
    "def contains_chinese(info):\n",
    "    text = info.get(\"question\", \"\")\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff]')\n",
    "    # re.Match\n",
    "    is_chinese = bool(pattern.search(text))\n",
    "    if is_chinese:\n",
    "        return \"chinese\"\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c6a3b1-c058-4495-a2e0-7682ec2f29a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'other'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_chinese({\"question\":\"what is your name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feb0e32-4cea-462d-aede-bbc1504f89ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入ZHIPUAI_API_KEY... ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] =  getpass.getpass(\"请输入ZHIPUAI_API_KEY...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab37d9fe-e8ca-4811-b378-6f181055bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTempalte\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama, ChatZhipuAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "zhipuai_chain = ChatPromptTemplate.from_template(\n",
    "    \"\"\"你是一个中文专家。回答问题时，你总是以`大小寒告诉我的:`开头。\n",
    "请回答下面的问题：\n",
    "问题：{question}\n",
    "回答：\"\"\") | ChatZhipuAI(model=\"glm-4\")\n",
    "\n",
    "ollama_chain = ChatPromptTemplate.from_template(\n",
    "    \"\"\"你是一个非中文专家。回答问题时，你总是以`苏格拉底告诉我的:`开头。\n",
    "请回答下面的问题：\n",
    "问题：{question}\n",
    "回答：\"\"\") | ChatOllama(model=\"llama3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "316ea4f3-95fd-4f4d-91f5-930cb9f6ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def route(info):\n",
    "    # print(f\"info:{info}\")\n",
    "    # return \"随便写一点返回\"\n",
    "    if info[\"topic\"] == \"chinese\":\n",
    "        return zhipuai_chain\n",
    "    else:\n",
    "        return ollama_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb84d8c5-1210-479f-9962-607215d1f1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='大小寒告诉我的：LangChain 是一种基于语言模型的连锁推理框架，它能够处理较长的文本序列，通过将文本分解成较短的片段，再利用语言模型对这些片段进行推理和链接，以此来完成复杂的文本生成或理解任务。这种方法可以有效地避免因为文本长度超出模型处理能力而导致的性能下降问题，提高模型在处理长文本时的效果。LangChain 框架适用于多种语言模型，并能应用于多种场景，如问答系统、文章生成、文本摘要等。', response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 37, 'total_tokens': 145}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-b59f1667-e381-4ffa-ae71-61302da3756e-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# chain = {\"topic\": contains_chinese, \"question\": lambda x: x[\"question\"]} | RunnableLambda(route)\n",
    "chain = {\"topic\": contains_chinese, \"question\": lambda x: x[\"question\"]} | route\n",
    "result = chain.invoke({\"question\": \"什么是langchain?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3ac9d-2bdf-4f17-98e9-ace400d08bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
